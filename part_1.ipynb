{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74e6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr=re.compile('<.()_:-*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d9a38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basepath='C:/Users/chhas/Pictures/Documents'\n",
    "d_ID=0\n",
    "word_id=0\n",
    "doc_dic={}\n",
    "word_dictionarr={}\n",
    "D_IND={}\n",
    "index_list=[]\n",
    "func={}\n",
    "dicionary_ind={}\n",
    "with os.scandir(basepath) as entries:\n",
    "    for y in entries:\n",
    "        if y.is_file():\n",
    "            file=open(basepath+'/'+y.name,'r',encoding='utf8').read()\n",
    "            clean_htm=cleanhtml(file)\n",
    "            liss=file.split()\n",
    "            tok_words = nltk.word_tokenize(clean_htm)\n",
    "            remove_stop=open('stopword.txt',encoding='utf8').read()\n",
    "            arr = [w for w in tok_words if not w in remove_stop]\n",
    "            with open('rida_docids.txt', 'a',encoding='utf8') as p:  \n",
    "                doc_dic[d_ID]=y.name\n",
    "                p.write( str(d_ID) +'_'+y.name)\n",
    "                p.write('\\n')\n",
    "                \n",
    "                with open('Term_ind.txt', 'a',encoding='utf8') as l:\n",
    "                    for i in range(len(arr)):\n",
    "                        if arr[i] in word_dictionarr:\n",
    "                            l.write( str(word_dictionarr[arr[i]]) +'_'+arr[i]+'\\n')\n",
    "                        else:\n",
    "                            l.write( str(word_id) +'_'+arr[i]+'\\n')\n",
    "                            word_dictionarr[arr[i]]=word_id\n",
    "                            word_id=word_id+1 \n",
    "            pp=[]\n",
    "            ee=[]\n",
    "            for i, e in enumerate(liss):\n",
    "                if e in word_dictionarr:\n",
    "                    pp.append(i)\n",
    "                    a=word_dictionarr[e]\n",
    "                    ee.append(a)\n",
    "            dicionary_ind[d_ID]=list(zip(pp, ee))\n",
    "            d_ID=d_ID+1\n",
    "            \n",
    "       \n",
    "       \n",
    "       \n",
    "           \n",
    "                  \n",
    "                    \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "260b8bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"rida_doc_index.txt\", 'w') as o:\n",
    "    j=1\n",
    "    for j in range(len(dicionary_ind)-1):\n",
    "        o.write(str(j) + \"\\t\")\n",
    "        \n",
    "        for k in dicionary_ind.get(j):\n",
    "            o.write( str(k[0])+\",\"+str(k[1])+\":\")\n",
    "        o.write('\\n')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc15d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaad732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
